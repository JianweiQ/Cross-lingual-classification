# Cross-lingual-classification
Cross-lingual Embeddings and Text Classification

## Packages
nltk, sklearn, thulac, numpy, keras

## Pre-data
Run following python code
```
nltk.download('wordnet')
```

## Inputs
Put wiki.zh.align.vec wiki.en.align.vec stopwords-zh.txt in subfolder data <br/>
Put Chinese corpus in subfolder data/sport data/politics data/science <br/>
put UM corpus txt in subfolder data/UM-Corpus <br/>
put RSV2 txt in subfolder data/RSV2 <br/>
